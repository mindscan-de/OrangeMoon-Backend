{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset - Kanji by stroke order 0x01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually the current implementation won't sort the kanji. But i like them to be sorted, when they are presented to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from jamdict import Jamdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jamdict = Jamdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radicals = list(jamdict.radk.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now now the raicals, we will now go through a loop, fetch every kanji for it, check, whether we already know it, if not, then we will lookup it and then get the stroke order. from the chars array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_kanji = set()\n",
    "for radical in radicals:\n",
    "    print(\"Processing {}\".format(radical))\n",
    "    kanjifor_radical = set(jamdict.radk[radical])\n",
    "    # print(kanjifor_radical)\n",
    "    processed_kanji = processed_kanji | kanjifor_radical\n",
    "    print(len(processed_kanji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kanji_strokes = {}\n",
    "kanji_freq = {}\n",
    "\n",
    "processed_kanji = set()\n",
    "for radical in radicals:\n",
    "    print(\"Processing {}\".format(radical))\n",
    "    kanjifor_radical = jamdict.radk[radical]\n",
    "    print(\"found: \"+str(len(kanjifor_radical)) +\" kanji.\")\n",
    "\n",
    "    for kanji in kanjifor_radical:\n",
    "        if kanji in processed_kanji:\n",
    "            continue\n",
    "        \n",
    "        # print(\"Kanji {}\".format(kanji))\n",
    "        result=jamdict.lookup(kanji,strict_lookup=True)\n",
    "        \n",
    "        for char in result.chars:\n",
    "            char_dict = char.to_json()\n",
    "            kanji_strokes[char_dict['literal']]=char_dict['stroke_count']\n",
    "        \n",
    "        frequency = int(result.chars[0].to_json()['freq'])\n",
    "        if(frequency==0):\n",
    "            frequency=10000\n",
    "        kanji_freq[char_dict['literal']]=frequency\n",
    "            \n",
    "        processed_kanji.add(kanji)\n",
    "    \n",
    "    \n",
    "    #processed_kanji = processed_kanji | kanjifor_radical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(kanji_strokes))\n",
    "print(len(kanji_freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = {}\n",
    "\n",
    "max_strokes = max(kanji_strokes.values())\n",
    "# init the stroke_tree\n",
    "for i in range(1+max_strokes):\n",
    "    tree[i]=list()\n",
    "\n",
    "for kanji, strokes in kanji_strokes.items():\n",
    "    tree[strokes].append(kanji)\n",
    "    # but what is the right criteria in the kanji stroke domain? (frequency?), i would opt for frequency.\n",
    "    # tree[strokes].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(kanji_strokes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kf(k):\n",
    "    if not k in kanji_freq:\n",
    "        return 10000\n",
    "    return int(kanji_freq[k])\n",
    "\n",
    "for strokes in tree.keys():\n",
    "    kanjilist = tree[strokes]\n",
    "    sorted_list = sorted(kanjilist, key=lambda kanji: kf(kanji), reverse=False)\n",
    "    tree[strokes] = sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanji_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(tree.keys())\n",
    "\n",
    "\n",
    "flattened = []\n",
    "for i in index:\n",
    "    flattened.extend(tree[i])\n",
    "\n",
    "flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "RADICAL_STROKE_DATA = 'kanjiStrokeData.json'\n",
    "\n",
    "with open(os.path.join(DATA_DIR,RADICAL_STROKE_DATA),'w') as outputFile:\n",
    "    json.dump( {'tree': tree, 'list':flattened }, outputFile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
