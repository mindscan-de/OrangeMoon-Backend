{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHK-Easy - Downloader 0x01\n",
    "\n",
    "(C) Maxim Gansert, Mindscan, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains some code, which can be used to download some easy japanese content from the NHK website. This code can read the main index of the HNK News WEB Easy and then can download, process and store the article content and some additional files, like the vocabulary / dictionary files.\n",
    "\n",
    "It would be very nice, if i could download the mp3 audio files as well from the akamai and extract the transport stream. This would be a nice resource for reading japanese news and listening to japanese news.\n",
    "\n",
    "The content might be then additionally annotated with N5-N1 vocabulary as well (in the future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_NEWS_CACHE_FOLDER = '../data/nhk_easy/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the catalog\n",
    "\n",
    "The catalog should be saved too, so we might be able to extract additional information from the json files as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request the json catalog of the news\n",
    "r = requests.get('https://www3.nhk.or.jp/news/easy/news-list.json')\n",
    "r.encoding = 'utf-8-sig'\n",
    "\n",
    "main_list = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointer to the NHK WEB NEWS EASY Articles\n",
    "\n",
    "A description for an NHK Article, e.g. title, locations. (Still TODO: Support all these timestamps.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataPointerNHK(object):\n",
    "    def __init__(self,pointer_data):\n",
    "        self.data = pointer_data\n",
    "        pass\n",
    "    \n",
    "    def getTitle(self):\n",
    "        return self.data['title']\n",
    "    \n",
    "    def getTitleWithRuby(self):\n",
    "        return self.data['title_with_ruby']\n",
    "        \n",
    "    def getNewsID(self):\n",
    "        return self.data['news_id']\n",
    "    \n",
    "    def hasWebImage(self):\n",
    "        return self.data['has_news_web_image']\n",
    "    \n",
    "    def getWebImageURI(self):\n",
    "        return self.data['news_web_image_uri']\n",
    "    \n",
    "    def hasWebMovie(self):\n",
    "        return self.data['has_news_web_movie']\n",
    "    \n",
    "    def getWebMovieURI(self):\n",
    "        return self.data['news_web_movie_uri']\n",
    "    \n",
    "    def hasEasyImage(self):\n",
    "        return self.data['has_news_easy_image']\n",
    "    \n",
    "    def getEasyImageURI(self):\n",
    "        return self.data['news_easy_image_uri']\n",
    "\n",
    "    def hasEasyMovie(self):\n",
    "        return self.data['has_news_easy_movie']\n",
    "    \n",
    "    def getEasyMovieURI(self):\n",
    "        return self.data['news_easy_movie_uri']\n",
    "\n",
    "    def hasEasyVoice(self):\n",
    "        return self.data['has_news_easy_voice']\n",
    "    \n",
    "    def getEasyVoiceURI(self):\n",
    "        return self.data['news_easy_voice_uri']\n",
    "    \n",
    "    # https://www3.nhk.or.jp/news/html/20210512/k10013025211000.html\n",
    "    def getNewsWebURL(self):\n",
    "        return self.data['news_web_url']\n",
    "    \n",
    "    # structure for the easy nwes article\n",
    "    # https://www3.nhk.or.jp/news/easy/k10013025211000/k10013025211000.html\n",
    "    def getNewsWebURLEasyIfPossible(self):\n",
    "        news_url = self.getNewsWebURL()\n",
    "        news_url = re.sub(r\"\\/html\\/.*\\/\",'/easy/'+self.getNewsID()+'/',news_url)\n",
    "        return news_url if self.hasEasyVoice() else self.getNewsWebURL()\n",
    "    \n",
    "    # https://www3.nhk.or.jp/news/easy/k10013025211000/k10013025211000.out.dic\n",
    "    def getVocabularyURLIfPossible(self):\n",
    "        news_url = self.getNewsWebURL()\n",
    "        news_url = re.sub(r\"\\/html\\/.*\\/\",'/easy/'+self.getNewsID()+'/',news_url)\n",
    "        news_url = re.sub(r\"\\.html\",'.out.dic',news_url)\n",
    "        return news_url if self.hasEasyVoice() else self.getNewsWebURL()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDacheDirectoryName(pointer:NewsDataPointerNHK):\n",
    "    web_url=pointer.getNewsWebURL()\n",
    "    web_url = re.sub('.*\\/html\\/','',web_url)\n",
    "    web_url = re.sub('\\.html','',web_url)\n",
    "    web_url = re.sub('\\/','_',web_url)\n",
    "    return os.path.join(LOCAL_NEWS_CACHE_FOLDER, web_url)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Building the Content Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_easy_nhk_news_article(news_date, nhk_pointer: NewsDataPointerNHK):\n",
    "    cache_dir = calcDacheDirectoryName(nhk_pointer)\n",
    "    \n",
    "    if os.path.isdir(cache_dir):\n",
    "        return\n",
    "        \n",
    "    os.mkdir(cache_dir)\n",
    "\n",
    "    news_uri = nhk_pointer.getNewsWebURLEasyIfPossible()\n",
    "    r = requests.get(news_uri)\n",
    "    r.encoding = 'utf-8'\n",
    "       \n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    title = soup.find('h1', attrs={'class':'article-main__title'})\n",
    "    article = soup.find('div', attrs={'id':'js-article-body'})\n",
    "    \n",
    "    for a in article.findAll('a'):\n",
    "        a.unwrap()\n",
    "    \n",
    "    # we should save the \n",
    "    with open(os.path.join(cache_dir, 'extracted.html'), 'w', encoding=\"utf-8\") as contentFile:\n",
    "        print(\"<!DOCTYPE html>\", file=contentFile)\n",
    "        print(\"<html lang='ja'>\", file=contentFile)\n",
    "        print(\"<head><meta charset='utf-8'></head>\", file=contentFile)\n",
    "        print(\"<style>p { font-size: 150%; line-height: 3.2; padding-bottom: 20px; }</style>\", file=contentFile)\n",
    "        print(\"<body>\", file=contentFile)\n",
    "        print(title, file=contentFile)\n",
    "        print(article, file=contentFile)\n",
    "        print(\"</body>\", file=contentFile)\n",
    "        print(\"</html>\", file=contentFile)\n",
    "\n",
    "    # we should also save the dictionary:\n",
    "    # e.g. https://www3.nhk.or.jp/news/easy/k10013023931000/k10013023931000.out.dic\n",
    "    with open(os.path.join(cache_dir, 'dict_vocab.json'), 'w', encoding=\"utf-8\") as vocabFile:\n",
    "        vocab_url = nhk_pointer.getVocabularyURLIfPossible()\n",
    "        vocab = requests.get(vocab_url)\n",
    "        vocab.encoding = 'utf-8-sig'\n",
    "        vocab_dict = json.loads(vocab.text)\n",
    "        json.dump(vocab_dict, vocabFile )\n",
    "\n",
    "    # we should also save the image for this article\n",
    "    if nhk_pointer.hasWebImage():\n",
    "        imageurl = nhk_pointer.getWebImageURI()\n",
    "        response = requests.get(imageurl, stream=True)\n",
    "        with open(os.path.join(cache_dir,'news_web_image.jpg'), 'wb') as out_file:\n",
    "            shutil.copyfileobj(response.raw, out_file)\n",
    "        del response\n",
    "\n",
    "    if nhk_pointer.hasEasyImage():\n",
    "        imageurl = 'https://www3.nhk.or.jp/news/easy/'+ nhk_pointer.getNewsID() + '/' + nhk_pointer.getEasyImageURI()\n",
    "        response = requests.get(imageurl, stream=True)\n",
    "        with open(os.path.join(cache_dir,'news_easy_image.jpg'), 'wb') as out_file:\n",
    "            shutil.copyfileobj(response.raw, out_file)\n",
    "        del response\n",
    "        \n",
    "    # TODO: we should also save the audio transport stream\n",
    "    # TODO: we should also save the movie if exists\n",
    "    \n",
    "    print(news_data_pointer.keys())\n",
    "    print(news_data_pointer)  \n",
    "\n",
    "def index_nhk_news_article(news_date, news_data_pointer):\n",
    "    nhk_pointer = NewsDataPointerNHK(news_data_pointer)\n",
    "    print(\"title: {}\\n       {}\".format(nhk_pointer.getTitle(), nhk_pointer.getTitleWithRuby()) )\n",
    "    print(\"url:   {}\".format(nhk_pointer.getNewsWebURL()))\n",
    "    print(\"easy:  {}\".format(nhk_pointer.getNewsWebURLEasyIfPossible()))\n",
    "    print(\"vocab: {}\".format(nhk_pointer.getVocabularyURLIfPossible()))\n",
    "    \n",
    "    if nhk_pointer.hasEasyVoice() :\n",
    "        index_easy_nhk_news_article(news_date, nhk_pointer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The keys of the dictionary are date-information\n",
    "\n",
    "When we inspect the keys, we might now know how to work from here. So we have for each date some news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_list[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Main Loop for building the index\n",
    "\n",
    "The index should work on a slow pace, e.g. one article per every 3 minutes or so. No need to bully the NHK website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getNHKNewsItems():\n",
    "    r = requests.get('https://www3.nhk.or.jp/news/easy/news-list.json')\n",
    "    r.encoding = 'utf-8-sig'\n",
    "    contents = json.loads(r.text)\n",
    "    indexfilename=\"index_{}.json\".format(int(time.time()))\n",
    "    # TODO: save the current json_list\n",
    "    with open( os.path.join( LOCAL_NEWS_CACHE_FOLDER+'/index_json/',indexfilename), 'w') as indexfile:\n",
    "        json.dump(contents, indexfile, indent=2)\n",
    "    \n",
    "    return contents[0].items()\n",
    "\n",
    "for news_date, news_for_the_day in getNHKNewsItems():\n",
    "    print(news_date)\n",
    "    for news_data_pointer in news_for_the_day:\n",
    "        index_nhk_news_article(news_date, news_data_pointer)\n",
    "        time.sleep(random.randint(30,75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup and Content Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www3.nhk.or.jp/news/easy/k10013025211000/k10013025211000.html\")\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "title = soup.find('h1', attrs={'class':'article-main__title'})\n",
    "article = soup.find('div', attrs={'id':'js-article-body'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in article.findAll('a'):\n",
    "    a.unwrap()\n",
    "\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www3.nhk.or.jp/news/easy/k10013023931000/k10013023931000.out.dic')\n",
    "r.encoding = 'utf-8-sig'\n",
    "\n",
    "vocab = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
